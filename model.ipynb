{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T04:09:17.693877Z",
     "start_time": "2024-10-22T04:09:17.591013Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.datasets import mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T04:09:18.171823Z",
     "start_time": "2024-10-22T04:09:17.599756Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"generated_data.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T04:09:18.330022Z",
     "start_time": "2024-10-22T04:09:18.179403Z"
    }
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for item in data:\n",
    "    keypoints = item[\"keypoints\"][0]\n",
    "    X.append(np.array(keypoints).flatten())\n",
    "    y.append(item[\"label\"])\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T04:09:18.341344Z",
     "start_time": "2024-10-22T04:09:18.335143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "print(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T04:09:18.348457Z",
     "start_time": "2024-10-22T04:09:18.341752Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "# (X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T04:09:18.371434Z",
     "start_time": "2024-10-22T04:09:18.349445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (32000, 34)\n",
      "y_train shape: (32000,)\n",
      "X_test shape: (8000, 34)\n",
      "y_test shape: (8000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T04:09:18.372110Z",
     "start_time": "2024-10-22T04:09:18.352813Z"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = len(label_encoder.classes_)\n",
    "input_shape = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T04:09:18.372531Z",
     "start_time": "2024-10-22T04:09:18.354461Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 17, 2, 1)\n",
    "X_test = X_test.reshape(-1, 17, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T04:09:18.400739Z",
     "start_time": "2024-10-22T04:09:18.362493Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikeshinoda/Library/Caches/pypoetry/virtualenvs/yolo-pose-estimation-DqWaCygJ-py3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "input_shape = (17, 2, 1)  # 高度、宽度、通道数\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 2), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T04:09:18.406296Z",
     "start_time": "2024-10-22T04:09:18.399804Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(128, activation=\"relu\", input_shape=(input_shape,)))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(64, activation=\"relu\"))\n",
    "# model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T04:09:58.863838Z",
     "start_time": "2024-10-22T04:09:18.403031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 926us/step - accuracy: 0.5578 - loss: 0.8776 - val_accuracy: 0.8728 - val_loss: 0.2769\n",
      "Epoch 2/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 879us/step - accuracy: 0.8620 - loss: 0.2976 - val_accuracy: 0.8903 - val_loss: 0.2361\n",
      "Epoch 3/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 866us/step - accuracy: 0.8864 - loss: 0.2520 - val_accuracy: 0.9047 - val_loss: 0.2042\n",
      "Epoch 4/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 867us/step - accuracy: 0.8974 - loss: 0.2279 - val_accuracy: 0.9234 - val_loss: 0.1803\n",
      "Epoch 5/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 948us/step - accuracy: 0.9142 - loss: 0.2039 - val_accuracy: 0.9322 - val_loss: 0.1666\n",
      "Epoch 6/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 956us/step - accuracy: 0.9197 - loss: 0.1950 - val_accuracy: 0.9438 - val_loss: 0.1453\n",
      "Epoch 7/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 940us/step - accuracy: 0.9267 - loss: 0.1757 - val_accuracy: 0.9497 - val_loss: 0.1338\n",
      "Epoch 8/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 953us/step - accuracy: 0.9311 - loss: 0.1721 - val_accuracy: 0.9450 - val_loss: 0.1412\n",
      "Epoch 9/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 942us/step - accuracy: 0.9294 - loss: 0.1696 - val_accuracy: 0.9556 - val_loss: 0.1184\n",
      "Epoch 10/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 873us/step - accuracy: 0.9326 - loss: 0.1611 - val_accuracy: 0.9491 - val_loss: 0.1328\n",
      "Epoch 11/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 975us/step - accuracy: 0.9374 - loss: 0.1575 - val_accuracy: 0.9463 - val_loss: 0.1378\n",
      "Epoch 12/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 924us/step - accuracy: 0.9309 - loss: 0.1619 - val_accuracy: 0.9559 - val_loss: 0.1145\n",
      "Epoch 13/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 853us/step - accuracy: 0.9421 - loss: 0.1406 - val_accuracy: 0.9434 - val_loss: 0.1362\n",
      "Epoch 14/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 862us/step - accuracy: 0.9438 - loss: 0.1406 - val_accuracy: 0.9547 - val_loss: 0.1198\n",
      "Epoch 15/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 842us/step - accuracy: 0.9448 - loss: 0.1392 - val_accuracy: 0.9572 - val_loss: 0.1299\n",
      "Epoch 16/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 861us/step - accuracy: 0.9477 - loss: 0.1374 - val_accuracy: 0.9613 - val_loss: 0.1030\n",
      "Epoch 17/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 867us/step - accuracy: 0.9498 - loss: 0.1296 - val_accuracy: 0.9525 - val_loss: 0.1198\n",
      "Epoch 18/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 843us/step - accuracy: 0.9499 - loss: 0.1270 - val_accuracy: 0.9456 - val_loss: 0.1357\n",
      "Epoch 19/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 852us/step - accuracy: 0.9543 - loss: 0.1219 - val_accuracy: 0.9453 - val_loss: 0.1280\n",
      "Epoch 20/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 861us/step - accuracy: 0.9575 - loss: 0.1145 - val_accuracy: 0.9697 - val_loss: 0.0800\n",
      "Epoch 21/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 851us/step - accuracy: 0.9560 - loss: 0.1207 - val_accuracy: 0.9606 - val_loss: 0.1198\n",
      "Epoch 22/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 852us/step - accuracy: 0.9479 - loss: 0.1333 - val_accuracy: 0.9638 - val_loss: 0.0986\n",
      "Epoch 23/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 853us/step - accuracy: 0.9491 - loss: 0.1289 - val_accuracy: 0.9706 - val_loss: 0.0870\n",
      "Epoch 24/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 857us/step - accuracy: 0.9507 - loss: 0.1290 - val_accuracy: 0.9725 - val_loss: 0.0765\n",
      "Epoch 25/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 869us/step - accuracy: 0.9539 - loss: 0.1217 - val_accuracy: 0.9622 - val_loss: 0.0999\n",
      "Epoch 26/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 854us/step - accuracy: 0.9575 - loss: 0.1151 - val_accuracy: 0.9784 - val_loss: 0.0647\n",
      "Epoch 27/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 856us/step - accuracy: 0.9632 - loss: 0.0983 - val_accuracy: 0.9688 - val_loss: 0.0871\n",
      "Epoch 28/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 862us/step - accuracy: 0.9541 - loss: 0.1254 - val_accuracy: 0.9491 - val_loss: 0.1183\n",
      "Epoch 29/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 859us/step - accuracy: 0.9534 - loss: 0.1250 - val_accuracy: 0.9647 - val_loss: 0.0914\n",
      "Epoch 30/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 991us/step - accuracy: 0.9548 - loss: 0.1153 - val_accuracy: 0.9609 - val_loss: 0.0978\n",
      "Epoch 31/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 858us/step - accuracy: 0.9585 - loss: 0.1136 - val_accuracy: 0.9400 - val_loss: 0.1418\n",
      "Epoch 32/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 853us/step - accuracy: 0.9593 - loss: 0.1085 - val_accuracy: 0.9809 - val_loss: 0.0643\n",
      "Epoch 33/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 849us/step - accuracy: 0.9617 - loss: 0.1101 - val_accuracy: 0.9581 - val_loss: 0.1086\n",
      "Epoch 34/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 855us/step - accuracy: 0.9615 - loss: 0.1096 - val_accuracy: 0.9675 - val_loss: 0.0846\n",
      "Epoch 35/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 860us/step - accuracy: 0.9666 - loss: 0.0948 - val_accuracy: 0.9753 - val_loss: 0.0759\n",
      "Epoch 36/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 835us/step - accuracy: 0.9662 - loss: 0.0956 - val_accuracy: 0.9722 - val_loss: 0.0816\n",
      "Epoch 37/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 844us/step - accuracy: 0.9665 - loss: 0.0964 - val_accuracy: 0.9678 - val_loss: 0.0863\n",
      "Epoch 38/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 831us/step - accuracy: 0.9590 - loss: 0.1092 - val_accuracy: 0.9569 - val_loss: 0.1127\n",
      "Epoch 39/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 855us/step - accuracy: 0.9653 - loss: 0.0988 - val_accuracy: 0.9747 - val_loss: 0.0697\n",
      "Epoch 40/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 839us/step - accuracy: 0.9625 - loss: 0.1045 - val_accuracy: 0.9778 - val_loss: 0.0688\n",
      "Epoch 41/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 835us/step - accuracy: 0.9689 - loss: 0.0919 - val_accuracy: 0.9684 - val_loss: 0.0904\n",
      "Epoch 42/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 831us/step - accuracy: 0.9648 - loss: 0.0997 - val_accuracy: 0.9663 - val_loss: 0.0949\n",
      "Epoch 43/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 846us/step - accuracy: 0.9699 - loss: 0.0895 - val_accuracy: 0.9669 - val_loss: 0.0937\n",
      "Epoch 44/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 838us/step - accuracy: 0.9685 - loss: 0.0917 - val_accuracy: 0.9491 - val_loss: 0.1578\n",
      "Epoch 45/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 840us/step - accuracy: 0.9632 - loss: 0.1075 - val_accuracy: 0.9141 - val_loss: 0.1854\n",
      "Epoch 46/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 853us/step - accuracy: 0.9482 - loss: 0.1317 - val_accuracy: 0.9141 - val_loss: 0.1923\n",
      "Epoch 47/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 848us/step - accuracy: 0.9546 - loss: 0.1245 - val_accuracy: 0.8556 - val_loss: 0.3198\n",
      "Epoch 48/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 843us/step - accuracy: 0.9554 - loss: 0.1219 - val_accuracy: 0.8403 - val_loss: 0.3158\n",
      "Epoch 49/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 866us/step - accuracy: 0.9619 - loss: 0.1072 - val_accuracy: 0.9087 - val_loss: 0.2094\n",
      "Epoch 50/50\n",
      "\u001B[1m900/900\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 858us/step - accuracy: 0.9613 - loss: 0.1087 - val_accuracy: 0.8319 - val_loss: 0.3514\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T04:09:58.973564Z",
     "start_time": "2024-10-22T04:09:58.864813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 - 0s - 350us/step - accuracy: 0.8290 - loss: 0.3590\n",
      "\n",
      "测试集准确率: 0.8289999961853027\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(\"\\n测试集准确率:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T04:09:59.172936Z",
     "start_time": "2024-10-22T04:09:58.971395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 391us/step\n",
      "预测的类别： [2 3 3 ... 1 0 2]\n",
      "真实的类别： [2 1 3 ... 1 0 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        jump       1.00      1.00      1.00      2047\n",
      "         run       1.00      0.31      0.47      1967\n",
      "       stand       1.00      1.00      1.00      2000\n",
      "        walk       0.59      1.00      0.74      1986\n",
      "\n",
      "    accuracy                           0.83      8000\n",
      "   macro avg       0.90      0.83      0.80      8000\n",
      "weighted avg       0.90      0.83      0.81      8000\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "print(\"预测的类别：\", y_pred_classes)\n",
    "print(\"真实的类别：\", y_test)\n",
    "y_test_labels = label_encoder.inverse_transform(y_test)\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred_classes)\n",
    "\n",
    "print(classification_report(y_test_labels, y_pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T04:09:59.188Z",
     "start_time": "2024-10-22T04:09:59.172184Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"pose.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-22T04:09:59.196768Z",
     "start_time": "2024-10-22T04:09:59.193241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "print(y_encoded)\n",
    "\n",
    "# 保存 LabelEncoder\n",
    "with open(\"label_encoder.pkl\", \"wb\") as le_file:\n",
    "    pickle.dump(label_encoder, le_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "Image: ./g1.png --> Predicted Label: jump\n",
      "Image: ./g2.png --> Predicted Label: jump\n",
      "预测完成，结果已保存到 predictions.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "# 加载标签编码器\n",
    "with open(\"label_encoder.pkl\", \"rb\") as le_file:\n",
    "    label_encoder = pickle.load(le_file)\n",
    "\n",
    "# 加载训练好的模型\n",
    "model = load_model(\"pose.keras\")\n",
    "\n",
    "\n",
    "# 定义一个函数来预处理关键点数据\n",
    "def preprocess_keypoints(keypoints):\n",
    "    \"\"\"\n",
    "    预处理关键点数据，使其符合模型输入要求。\n",
    "\n",
    "    参数:\n",
    "        keypoints (list): 关键点列表，每个关键点为 [x, y]。\n",
    "\n",
    "    返回:\n",
    "        numpy.ndarray: 预处理后的关键点数据，形状为 (17, 2, 1)。\n",
    "    \"\"\"\n",
    "    keypoints_array = np.array(keypoints).flatten()  # 将关键点展平成一维数组\n",
    "    keypoints_array = keypoints_array.reshape(-1, 17, 2, 1)  # 重新调整形状以匹配模型输入\n",
    "    return keypoints_array\n",
    "\n",
    "\n",
    "# 加载 annotations.json 数据\n",
    "with open(\"annotations.json\", \"r\") as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "# 提取关键点并进行预处理\n",
    "X_new = []\n",
    "image_paths = []  # 用于存储图像路径（可选）\n",
    "for item in annotations:\n",
    "    keypoints = item[\"keypoints\"][0]  # 假设每个条目只有一个关键点集\n",
    "    X_new.append(preprocess_keypoints(keypoints))\n",
    "    image_paths.append(item[\"image_path\"])\n",
    "\n",
    "X_new = np.vstack(X_new)  # 合并所有样本，形状为 (样本数, 17, 2, 1)\n",
    "\n",
    "# 进行预测\n",
    "y_pred = model.predict(X_new)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred_classes)\n",
    "\n",
    "# 打印预测结果\n",
    "for img_path, pred_label in zip(image_paths, y_pred_labels):\n",
    "    print(f\"Image: {img_path} --> Predicted Label: {pred_label}\")\n",
    "\n",
    "# 可选：将预测结果保存到一个新的 JSON 文件中\n",
    "predictions = []\n",
    "for img_path, pred_label in zip(image_paths, y_pred_labels):\n",
    "    predictions.append({\n",
    "        \"image_path\": img_path,\n",
    "        \"predicted_label\": pred_label\n",
    "    })\n",
    "\n",
    "with open(\"predictions.json\", \"w\") as f:\n",
    "    json.dump(predictions, f, indent=4)\n",
    "\n",
    "print(\"预测完成，结果已保存到 predictions.json\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-22T04:09:59.285709Z",
     "start_time": "2024-10-22T04:09:59.199212Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-22T04:09:59.286141Z",
     "start_time": "2024-10-22T04:09:59.284494Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
